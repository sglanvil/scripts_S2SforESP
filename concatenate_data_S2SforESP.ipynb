{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9280ec14-638d-426c-970b-cc3be3881847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27dec1999\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# location of this script: /glade/u/home/sglanvil/analysis/python/analysis/concatenate_data_S2SforESP.ipynb\n",
    "# contact: sglanvil@ucar.edu\n",
    "\n",
    "# -------------------------------------- USER SPECIFIES --------------------------------------\n",
    "varname = \"tas_2m\"  # [\"tas_2m\", \"pr_sfc\"]\n",
    "method = \"allLeads\"  # [\"allLeads\", \"weeks12lead\", \"weeks34lead\", \"weeks45lead\"]\n",
    "calculate_ensemble_mean = False  # [True, False]\n",
    "start_date = \"1999-01-01\" # [eg, 1999-01-01] Note: doesn't need to be a monday\n",
    "end_date = \"1999-12-31\"  # [eg, 2020-12-31] Note: doesn't need to be a monday\n",
    "destDir = \"/glade/campaign/cesm/development/cross-wg/S2S/sglanvil/forJudith/\" \n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "# Check the time range if calculate_ensemble_mean is False\n",
    "if not calculate_ensemble_mean:\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    time_range = (end - start).days\n",
    "    if time_range > 370:\n",
    "        print(f\"Warning: Your time range is {time_range} days, which exceeds the 370-day limit.\")\n",
    "        print(\"When choosing to keep all members, you need to shorten your date range to less than 370 days.\")\n",
    "        raise ValueError(\"Time range exceeds the allowed limit.\")  # This will stop execution\n",
    "\n",
    "base_dir = f\"/glade/campaign/cesm/development/cross-wg/S2S/CESM2/S2SHINDCASTS/p1/{varname}\"\n",
    "mondays = pd.date_range(start_date, end_date, freq=\"W-MON\")\n",
    "methods = {\n",
    "    \"allLeads\": (None, np.arange(1, 47)),  # No time slicing, set time coords\n",
    "    \"weeks12lead\": (slice(0, 14), None),\n",
    "    \"weeks34lead\": (slice(14, 28), None),\n",
    "    \"weeks56lead\": (slice(28, 42), None),\n",
    "}\n",
    "time_slice, time_coords = methods.get(method, (None, None))\n",
    "\n",
    "data_results, init_array = [], []\n",
    "for monday in mondays:\n",
    "    short_date = monday.strftime(\"%d%b%Y\").lower()\n",
    "    init_date = pd.Timestamp(monday.strftime(\"%Y%m%d\"))\n",
    "    dir_path = os.path.join(base_dir, str(monday.year), f\"{monday.month:02d}\")\n",
    "    clear_output(wait=True)  # Clears the current output\n",
    "    print(short_date)\n",
    "    if not os.path.exists(dir_path): \n",
    "        continue\n",
    "    files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith(\".nc\") and short_date in f]\n",
    "    if not files:\n",
    "        continue\n",
    "    datasets = [xr.open_dataset(fp)[[varname]] for fp in files]\n",
    "    combined = xr.concat(datasets, dim=\"member\")\n",
    "\n",
    "    # Apply time slicing if specified\n",
    "    if time_slice:\n",
    "        combined = combined.isel(time=time_slice).mean(dim=\"time\")\n",
    "\n",
    "    # Calculate or keep all ensemble members\n",
    "    data = combined.mean(dim=\"member\").expand_dims(init=[init_date]) if calculate_ensemble_mean else combined.expand_dims(init=[init_date])\n",
    "\n",
    "    # Assign time coordinates if available\n",
    "    if time_coords is not None:\n",
    "        data = data.assign_coords({\"time\": time_coords})\n",
    "    data_results.append(data[varname])\n",
    "\n",
    "# Combine results across all dates\n",
    "data_combined = xr.concat(data_results, dim=\"init\")\n",
    "dataset = data_combined.to_dataset(name='data')\n",
    "dataset = dataset.convert_calendar(calendar=\"noleap\", dim=\"init\")\n",
    "date = dataset.init.dt.strftime(\"%Y%m%d\")\n",
    "dataset['date'] = date\n",
    "\n",
    "# Save raw concatenated DATA\n",
    "dataset.to_netcdf(f\"{destDir}/{varname}_cesm2cam6v2_allLeads_EM.nc\")\n",
    "\n",
    "# Calculate and save CLIM\n",
    "climatology = dataset.groupby('init.dayofyear').mean()\n",
    "climatology.to_netcdf(f\"{destDir}/{varname}_clim_cesm2cam6v2_allLeads_EM.nc\")\n",
    "\n",
    "# Calculate and save SMOOTH CLIM\n",
    "climCyclical = xr.concat([climatology, climatology, climatology], dim=\"dayofyear\")\n",
    "climSmooth0 = climCyclical.rolling(dayofyear=31, center=True).mean()\n",
    "climSmooth0 = climSmooth0.rolling(dayofyear=31, center=True).mean()\n",
    "climSmooth = climSmooth0.isel(dayofyear=slice(365, 365+365))\n",
    "climSmooth.to_netcdf(f\"{destDir}/{varname}_climSmooth_cesm2cam6v2_allLeads_EM.nc\")\n",
    "\n",
    "# Calculate and save ANOMALIES\n",
    "anomalies = dataset.groupby('init.dayofyear')-climSmooth\n",
    "anomalies['date'] = date\n",
    "anomalies.to_netcdf(f\"{destDir}/{varname}_anom_cesm2cam6v2_allLeads_EM.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fd059-9a0a-438a-a9cd-5c1ae99973c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
